- structure output (json for dataset item)
- make unitaire tests for pipeline and set the api key in github action
- ajouter des nouveaux evaluators
- ajouter des nouveaux dataset items
- prompts opti on langfuse + syncro with codebase ==> more generic or make prompt specific auto
- ajouter le dataset dans l'analyse
- chercher dans la SRS des termes spécifiques du req
- separate tests cases generation from the main graph to evaluate it

- enlever le filtre scenario pour deep agent (il recup tous les tests et dataset d'un req donné)
- refactor le usage de mistral car code répété


low prio:
- auto detect the format of req id 
(compliqué en full auto car par exemple req SSS comment peut on savoir que ce n'est pas ça le req SRS)

done:
- améliorer le rag (use regex)
- srs avec images et tableau

problems:
- a given req don't give you always the way to test 
(for instance a req talks about eligibility conditions and another said
 that when all conditions are met you raised an alert => you need to rag all srs to know how to test)
- a given req could said you need OPERATIONAL status but you don't know with the SRS the others status 
so you can't test all the transitions
